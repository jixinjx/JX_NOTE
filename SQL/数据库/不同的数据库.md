## **OLTP & OLAP**

### **OLTP (On-Line Transaction Processing)**

-   主要做实时事务处理
-   比如处理用户基本信息、处理订单合同、处理银行转账业务、企业的 ERP 系统和 OA 系统，等等
-   频繁地，对少量数据，甚至是单条数据，做实时的增删改查
-   数据库经常更新
-   通常对规范化、实时性、稳定性、事务性、一致性、完整性等有要求
-   操作较为固定，比如订单业务，可能永远就那几个固定的操作
-   数据库主要模型是 3NF 或 BCNF 模型

OLAP (On-Line Analytical Processing)

-   数据仓库，主要做历史数据分析，为商业决策提供支持
-   比如对大量的用户行为做分析，对设备的状态、使用率、性能做分析
-   频率较低地，对大量数据，做读取、聚合、计算、分析，实时性要求不高，对吞吐能力要求较高
-   通常列的数量比较多，但每次分析的时候只取少部分列的数据
-   通常是批量导入数据
-   通常数据导入后不会修改，主要是读取操作，写少读多
-   通常对规范化、事务性、一致性、完整性等要求较低，甚至一个查询操作失败了也不会有什么影响
-   操作较为灵活，比如一个海量用户行为数据表，可以想出许多不同的方法，从不同的角度对用户做分析
-   数据库主要是星型、雪花模型
-   不使用高性能的 OLAP 之前，更传统的做法是通过离线业务构建 T+1 的离线数据，比较滞后

OLTP 通常用传统的关系数据库，如果数据量大要分表，对事务性、一致性、完整性等要求不高的话也可以用 NoSQL


## 关系型数据库
**Oracle**：甲骨文开发的商业数据库，不开源，支持所有主流平台，性能好，功能强，稳定性好，安全性好，支持大数据量，比较复杂，收费昂贵。


### **HBase (宽表、列式存储、键值对存储、NoSQL、OLTP)**

-   基于 Hadoop 的 HDFS 分布式文件系统
-   分布式数据库，需要 ZooKeeper 作为节点间的协调器
-   支持宽表，支持非结构化数据，不需要预定义列和数据类型
-   列式存储，每个 HFile 文件只存储一个列族的数据，一个列族可以有多个 HFile，而 HFile 内部按 Key-Value 格式存储，其中 Key 是 rowkey, column family, column, timestamp 的组合并且按 rowkey 在 HFile 中按序存储，而 value 就是 Column Cell 的值
-   支持海量数据 (千亿级数据表)
-   数据先写入内存，达到阀值再写入磁盘，性能好，占用内存大
-   不支持 SQL，不支持 Join，有自己专用的语句，支持增删改查
-   自动分区、负载均衡、可线性扩展
-   自动故障迁移
-   强一致性 (每个分区 Region 只由一个 Region Server 负责，容易实现强一致性)
-   CP 模型 (不保证可用性，每个 Region 只由一个 Region Server 负责，Server 挂了得做迁移导致暂时不可用)
-   不支持事务、二级索引

## **Hive (基于 HDFS 的数据库引擎、关系型、OLAP)**

-   Hive 是基于 Hadoop 的一个数据仓库工具
-   数据存储在 HDFS，创建表的时候要通过 STORED AS 命令指定存储格式比如 TEXTFILE、ORCFILE、PARQUET，也可以通过 STORED BY 命令指定为 HBase，可以创建新表也可以创建已有 HBase 表的映射
-   查询通过 MapReduce、Spark 等作业完成
-   提供了类 SQL 查询语言 HQL (HiveQL)，支持用户定义函数 (UDF)
-   高版本支持事务 (需要创建表时指定)
-   支持海量数据
-   结构化数据
-   支持增删改查

### **应用场景**

-   不适合于 OLTP，主要作为 OLAP 用于大数据批量查询使用，需要有 Hadoop 平台
### **Impala (基于 HDFS、HBase、Kudu 存储，并行计算，关系型，OLAP)**

-   Cloudera 开发的基于内存的分布式并行计算的数据库查询引擎
-   主要由 C++ 实现，和 Hadoop 的交互使用 JNI
-   Impala 使用和 Hive 一样的 metadata、SQL、ODBC driver、UI，这样在提高了 HDFS 的 SQL 查询性能的同时，又提供了相似的用户使用体验
-   和 Hive 一样可以通过 STORED AS 指定 HDFS 的存储格式比如 TEXTFILE、ORCFILE、PARQUET
-   通过 Hive 操作的表，需要手动同步到 Impala
-   Impala 不仅 SQL 和 Hive 一样，实际上元数据也存在 Hive 中
-   表数据除了 HDFS，也可以存储到 HBase，但需要在 HBase 建表，然后在 Hive 通过 STORED BY 建立映射表，由于 Impala 和 Hive 使用一样的 metadata，在 Hive 建好表后，只要在 Impala 执行刷新命令 INVALIDATE METADATA，就可以看到对应的 HBase 表
-   支持 Join、Aggregate 等功能
-   支持 JDBC、ODBC
-   和 Hive 不同，Impala 不依赖于 MapReduce，而是在每个 HDFS DataNode 上运行自己的引擎实现并行处理
-   Impala 的并行处理引擎主要由 state store、catalog service、多个 impala daemon 组成
-   每个 impala daemon 都可以接收 client 的请求，impala daemon 由 query planner、query coordinator、query executor 组成，planner 接收 client 的 SQL 查询，然后分解为多个子查询，由 coordinator 将子查询分发到各个 daemon 的 executor 执行，daemon 获取 HDFS、HBase 数据、计算、然后返回给 coordinator，然后由 coordinator 聚合后将最终结果返回给 client
-   Impala 是无中心结构，每个 daemon 都可以接受连接查询，可以通过 HA Proxy 实现多个 daemon 的负载均衡
-   state store 用于收集监控各个 daemon 的状态
-   catalog service 将 SQL 做出的元数据变化通知给集群中所有的 impala daemon
-   Impala 的计算都在内存进行，对内存要求比较高
-   Impala 在 2.8 以后才支持 update 操作，但是只限于 Kudu 存储，需要安装 Kudu，并通过 STORED AS 指定 Kudu 作为数据库的存储，Kudu 是 Cloudera 开发的列式存储管理器，目的是做 OLAP，并且平衡 HDFS 和 HBase 的性能，Kude 的随机读写性能比 HDFS（比如 Parquet）好，但是比 HBase 差，而大数据量查询性能比 HDFS（比如 Parquet）差，但比 HBase 好，Kude 和 Impala 高度集成，也可以和 MapReduce/Spark 集成，用 Kudu 替换 HDFS/HBase 这样 Impala 就可以做 update，兼顾 OLAP 和改数据的需求，适合于以 OLAP 为主又有一定的 Update 需求的场景，Kudu 可以配置一致性，采用结构化表数据模型，需要定义主键，不使用 HDFS 而是有自己的组件存储和管理数据, 采用 c++ 没有 full gc 风险

### **应用场景**

-   Impala 不适合于 OLTP，主要作为 OLAP 用于大数据批量查询使用
-   需要有 Hadoop 平台和 Hive
-   性能比 Hive 好很多
-   作为 OLAP 的性能比 Phoenix 之类的好
-   主要是 CDH 在推，CDH 有集成 Impala


### **Greenplum (基于多个 PostgreSQL，并行计算，关系型，OLAP)**

-   基于多个 PostgreSQL 的分布式并行计算的数据库查询引擎
-   内部的 PostgreSQL 有做改动以适应并行分布式计算
-   主要由一个 master、多个 segments、一个 interconnect 组成
-   master 维护元数据，接收并认证 client 的链接，接收 SQL 请求，解析 SQL，生成 query plan，并将任务分发到 segments，协调聚合 segments 的返回结果，并将最终结果返回给 client，可以设置 master 为主从配置
-   每个 segment 有个独立的 PostgreSQL 数据库，每个 segment 负责存储部分数据，并执行相应的查询计算，segment 也可以配置备份机制
-   Interconnect 是 Greenplum 的网络层，负责 master 和 segment 的链接，以及各个 segment 之间的链接
-   链接和 SQL 语法都和 PostgreSQL 兼容，支持 JDBC、ODBC
-   创建表时可以指定是用列存储、行存储、外部表 (数据在其他系统比如 HDFS 而 GP 只存储元数据)
-   操作外部数据，需要安装 PXF (Platform Extension Framework)，有了 PXF 可以支持 Hive、HBase、Parquet、S3、MySQL、ORACLE 等等
-   支持安全、权限配置
-   支持分布式事务，支持 ACID，保证数据的强一致性，不是使用锁，而是使用 MVCC (Multi-Version Concurrency Control) 来保证数据一致性
-   shared-nothing 架构

### **应用场景**

和 Impala、Presto 类似都是并行内存计算，但 Greenplum 性能可能稍差一点点，并且 Greenplum 还分开源版和商业版，有的功能只有商业版才支持